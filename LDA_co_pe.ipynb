{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "origin = pd.read_excel('./filename')  # 데이터 입력\n",
    "origin = origin.iloc[:,2]   # 발화가 있는 셀을 참조\n",
    "\n",
    "import re\n",
    "def def_pre(origin):\n",
    "    dialogue_list = []  \n",
    "    for sentece in origin:\n",
    "        sentece = re.sub(r'\\([^)]*\\)', '', str(sentece))\n",
    "        sentece = re.sub('[.,?/*!\"]', '', str(sentece))\n",
    "        if sentece[:1] =='아':\n",
    "            dialogue_list.append(sentece[2:])\n",
    "    return dialogue_list\n",
    "         \n",
    "def def_remove_space(dialogue_list):\n",
    "    strip_senten = []\n",
    "    for i in dialogue_list:\n",
    "        strip_senten.append(i.strip())\n",
    "    return strip_senten\n",
    "    \n",
    "def def_remove_space2(strip_senten):\n",
    "    full_senten = []  \n",
    "    for i in range(len(strip_senten)):\n",
    "        if( len(strip_senten[i]) > 0):\n",
    "            full_senten.append(strip_senten[i])\n",
    "        else:\n",
    "            continue\n",
    "    return full_senten\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "def def_kkmaNoun(full_senten):\n",
    "    origin_noun_kkma = []\n",
    "    for i in range(len(full_senten)):\n",
    "        nouns = kkma.pos(full_senten[i])\n",
    "        # print(nouns)\n",
    "        etc = []\n",
    "        for word in nouns:\n",
    "            if (len(word[0])>1) and (word[1][0] == 'N'):\n",
    "                etc.append(word[0])\n",
    "            else:\n",
    "                continue\n",
    "        origin_noun_kkma.append(etc)\n",
    "    return origin_noun_kkma\n",
    "\n",
    "def bind_document(documents):\n",
    "    new_documents=[]\n",
    "    for i in range(len(documents)-2):\n",
    "        new_documents.append(documents[i]+ ' ' + documents[i+1]+ ' ' + documents[i+2])\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발화의 수 :  49\n"
     ]
    }
   ],
   "source": [
    "dialogue_list = def_pre(origin)\n",
    "strip_senten = def_remove_space(dialogue_list)\n",
    "full_senten = def_remove_space2(strip_senten)\n",
    "\n",
    "sentence_3 = bind_document(full_senten)\n",
    "print(\"발화의 수 : \",len(sentence_3))\n",
    "\n",
    "#명사 추출\n",
    "origin_noun_kkma = def_kkmaNoun(sentence_3)\n",
    "origin_noun_kkma2 = def_remove_space2(origin_noun_kkma)\n",
    "dictionary_noun = []\n",
    "\n",
    "for i in range(len(origin_noun_kkma2)):\n",
    "    for j in range(len(origin_noun_kkma2[i])):\n",
    "        if origin_noun_kkma2[i][j] not in dictionary_noun:\n",
    "            dictionary_noun.append(origin_noun_kkma2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 수 :  3   Coherence Score :  0.360805989639881   Perplexity :  20.62402293874072\n",
      "topic 수 :  4   Coherence Score :  0.3687651363366631   Perplexity :  19.59981381996606\n",
      "topic 수 :  5   Coherence Score :  0.34025368286316243   Perplexity :  20.782470812522885\n",
      "topic 수 :  6   Coherence Score :  0.3809812842751124   Perplexity :  20.44971430736325\n",
      "topic 수 :  7   Coherence Score :  0.38328528136274376   Perplexity :  19.392491605025462\n",
      "topic 수 :  8   Coherence Score :  0.39317396569103513   Perplexity :  19.219521709546797\n",
      "topic 수 :  9   Coherence Score :  0.39318139722829776   Perplexity :  20.339783803379078\n",
      "topic 수 :  10   Coherence Score :  0.3833526269183719   Perplexity :  19.975597442318495\n",
      "topic 수 :  11   Coherence Score :  0.4281386243771206   Perplexity :  19.955556714797055\n",
      "topic 수 :  12   Coherence Score :  0.3927137059198262   Perplexity :  19.096071997603982\n",
      "topic 수 :  13   Coherence Score :  0.43727522109156136   Perplexity :  19.341158890207435\n",
      "topic 수 :  14   Coherence Score :  0.4342546336521324   Perplexity :  20.105089987515537\n",
      "topic 수 :  15   Coherence Score :  0.41597915891269854   Perplexity :  19.348478818566303\n",
      "topic 수 :  16   Coherence Score :  0.39471117174624676   Perplexity :  21.406889061411018\n",
      "topic 수 :  17   Coherence Score :  0.4132441309563117   Perplexity :  22.210115029008225\n",
      "topic 수 :  18   Coherence Score :  0.437665419589898   Perplexity :  20.24843818135355\n",
      "topic 수 :  19   Coherence Score :  0.4183505098226528   Perplexity :  21.04587496275658\n",
      "topic 수 :  20   Coherence Score :  0.44533829719792006   Perplexity :  21.934120382763833\n",
      "topic 수 :  21   Coherence Score :  0.43694935931164924   Perplexity :  22.786744977670157\n",
      "topic 수 :  22   Coherence Score :  0.44072056486790034   Perplexity :  21.66844605325708\n",
      "topic 수 :  23   Coherence Score :  0.43870639781876203   Perplexity :  22.573207852628133\n",
      "topic 수 :  24   Coherence Score :  0.4430350679131702   Perplexity :  21.76833610028473\n",
      "topic 수 :  25   Coherence Score :  0.43736978375615637   Perplexity :  22.963831013689283\n",
      "topic 수 :  26   Coherence Score :  0.4458755677320838   Perplexity :  25.09488157868053\n",
      "topic 수 :  27   Coherence Score :  0.4406872703110373   Perplexity :  23.808628703262134\n",
      "topic 수 :  28   Coherence Score :  0.4458365463307933   Perplexity :  21.738829708910053\n",
      "topic 수 :  29   Coherence Score :  0.4456095829810665   Perplexity :  24.9171565593552\n"
     ]
    }
   ],
   "source": [
    "# LDA model\n",
    "\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "id2word = corpora.Dictionary(origin_noun_kkma2)\n",
    "texts = origin_noun_kkma2\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "lda_model = []\n",
    "\n",
    "for i in range(3,30):\n",
    "\n",
    "    lda_model.append(gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=i,\n",
    "    random_state=100,\n",
    "    update_every=1,\n",
    "    chunksize=100,\n",
    "    passes=50,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True))\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "\n",
    "Coherence_scores = []\n",
    "Perplexity_scores = []\n",
    "\n",
    "for i, lda_model_num in enumerate(lda_model):\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model_num, texts=origin_noun_kkma2, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(\"topic 수 : \", i+3, \"  Coherence Score : \", coherence_lda, \"  Perplexity : \", np.exp2(-lda_model_num.log_perplexity(corpus)))\n",
    "    Coherence_scores.append(coherence_lda)\n",
    "    Perplexity_scores.append(np.exp2(-lda_model_num.log_perplexity(corpus))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토픽  3 개   Coherence :  -1.782310790392596   Perplexity :  -0.34831061553916043   co-per :  -1.4340001748534357\n",
      "토픽  4 개   Coherence :  -1.5189807626287888   Perplexity :  -0.9678688902045455   co-per :  -0.5511118724242433\n",
      "토픽  5 개   Coherence :  -2.462288144788096   Perplexity :  -0.2524634770084901   co-per :  -2.209824667779606\n",
      "토픽  6 개   Coherence :  -1.1148069612966398   Perplexity :  -0.4537522450123869   co-per :  -0.6610547162842528\n",
      "토픽  7 개   Coherence :  -1.0385787373214506   Perplexity :  -1.0932810883149655   co-per :  0.05470235099351495\n",
      "토픽  8 개   Coherence :  -0.7114095547545191   Perplexity :  -1.1979128829434578   co-per :  0.4865033281889387\n",
      "토픽  9 개   Coherence :  -0.7111636807948789   Perplexity :  -0.5202510645832671   co-per :  -0.19091261621161182\n",
      "토픽  10 개   Coherence :  -1.036350595573479   Perplexity :  -0.7405519373363455   co-per :  -0.2957986582371336\n",
      "토픽  11 개   Coherence :  0.44540346720943486   Perplexity :  -0.7526752174679658   co-per :  1.1980786846774008\n",
      "토픽  12 개   Coherence :  -0.7266373452386444   Perplexity :  -1.27258935145101   co-per :  0.5459520062123656\n",
      "토픽  13 개   Coherence :  0.747689674278985   Perplexity :  -1.1243330302084744   co-per :  1.8720227044874593\n",
      "토픽  14 개   Coherence :  0.6477529091218079   Perplexity :  -0.662220597125582   co-per :  1.30997350624739\n",
      "토픽  15 개   Coherence :  0.043105017347483496   Perplexity :  -1.1199051075631916   co-per :  1.163010124910675\n",
      "토픽  16 개   Coherence :  -0.6605507719453986   Perplexity :  0.1252555712769226   co-per :  -0.7858063432223212\n",
      "토픽  17 개   Coherence :  -0.04738395278059883   Perplexity :  0.6111384269053366   co-per :  -0.6585223796859354\n",
      "토픽  18 개   Coherence :  0.7605994729439512   Perplexity :  -0.5755071379499831   co-per :  1.3361066108939343\n",
      "토픽  19 개   Coherence :  0.12156165657596432   Perplexity :  -0.09312599045250262   co-per :  0.21468764702846693\n",
      "토픽  20 개   Coherence :  1.0144582282255485   Perplexity :  0.4441856432693526   co-per :  0.5702725849561959\n",
      "토픽  21 개   Coherence :  0.7369084693558349   Perplexity :  0.9599498378043715   co-per :  -0.22304136844853661\n",
      "토픽  22 개   Coherence :  0.8616795913948504   Perplexity :  0.28347630810703084   co-per :  0.5782032832878196\n",
      "토픽  23 개   Coherence :  0.7950404546661636   Perplexity :  0.8307781234112089   co-per :  -0.03573766874504536\n",
      "토픽  24 개   Coherence :  0.9382554071687629   Perplexity :  0.34390018317846377   co-per :  0.5943552239902992\n",
      "토픽  25 개   Coherence :  0.7508182997512723   Perplexity :  1.067070896529471   co-per :  -0.3162525967781987\n",
      "토픽  26 개   Coherence :  1.032233935857023   Perplexity :  2.3561740485586937   co-per :  -1.3239401127016708\n",
      "토픽  27 개   Coherence :  0.8605780340398808   Perplexity :  1.5781020758175952   co-per :  -0.7175240417777144\n",
      "토픽  28 개   Coherence :  1.0309429046602525   Perplexity :  0.3260521837418535   co-per :  0.704890720918399\n",
      "토픽  29 개   Coherence :  1.0234337749178544   Perplexity :  2.2486653345609917   co-per :  -1.2252315596431373\n",
      "최적의 topic 수 :  13\n"
     ]
    }
   ],
   "source": [
    "# Standardization Coherence, Perplexity Score\n",
    "import numpy as np\n",
    "\n",
    "co_mean = np.mean(Coherence_scores)\n",
    "co_std = np.std(Coherence_scores)\n",
    "per_mean = np.mean(Perplexity_scores)\n",
    "per_std = np.std(Perplexity_scores)\n",
    "\n",
    "stan = []\n",
    "\n",
    "for i in range(len(Coherence_scores)):\n",
    "    co_standard = (Coherence_scores[i] - co_mean) / co_std\n",
    "    per_standard = (Perplexity_scores[i] - per_mean) / per_std\n",
    "    print(\"토픽 \", i+3, \"개   Coherence : \", co_standard, \"  Perplexity : \", per_standard, \"  co-per : \", co_standard - per_standard)\n",
    "    stan.append(co_standard - per_standard)\n",
    "\n",
    "print(\"최적의 topic 수 : \", stan.index(max(stan))+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
