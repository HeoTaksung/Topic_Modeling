# Topic_Modeling
LDA_Coherence, LDA_Perplexity

 * [LDA와 선호도 전파 알고리즘을 이용한 아동 발화의 화제수 측정](http://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE09301947)
 
   * `오세은`, `허탁성`, `이윤경`, `김유섭`
   
-----------------------------------------------

## 데이터

 * 한림대학교 언어병리학과에서 수집한 아동 발화 데이터 (주제 - 학교생활, 가정생활, 기타/친구)
 
   * 1학년, 3학년, 5학년의 집단 데이터
   
     * 데이터 예시 (주제 변환 발화 2-3)

        |    턴    | 발화  | 대화  |
        | :------: | :---: | :-----: |
        |  <학교>  |      | 검 학교생활은 어때?          |
        |    1     |   1  | 아 재미없어요.               |
        |          |      | 검 재미없구나. 그리고?       |
        |    2     |   2  | 아 점심 먹고 양치하고        |
        |          |   3  | 아 근데 엄마 보고싶다.       |
        
-----------------------------------------------

## Latent Dirichlet Allocation

 * LDA 토픽 모델링
 
   * LDA는 화제 수 K를 사용자가 정의하여 판단하나, 연구 목적은 대화 내용의 화제 수를 맞추기 위해 Coherence와 Perplexity를 이용하여 화제 수를 측정한다.
   
   * K를 3-29까지를 설정 (본 연구에서 이용하는 데이터의 최소 주제 수는 3개이므로 K를 3부터 설정)
   
   * LDA를 통해 나온 3~29의 topic을 가지는 Coherence와 Perplexity를 수식 (1)인 Standardization을 진행
   
     * *Standardization(x) = (x - mean(x)) / std(x)* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)
   
   * 수식 (2)에서 값이 제일 큰 것을 예측 결과로 정의
   
     * *f(co,pe) = Standardization(co) - Standardization(pe)* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)

-----------------------------------------------

## 실험 결과

 * 학령기에 따른 대화의 화제수 비교
 
    |   학년  | LDA | 언어병리학  |
    | :-----: | :--: | :-----: |
    |    1    |  19  | 19.5 |
    |    3    |   4  | 17.2 |
    |    5    |   4  | 12.5 |
    
    **LDA와 언어 병리학과의 상관 계수 - 0.7525**
    
-----------------------------------------------

## 결론

  * LDA 토픽 모델링과 언어 병리학과의 상관 계수를 보았을 때, 높은 상관 계수를 확인할 수 있었다.
  
  * 하지만 LDA에서의 3학년과 5학년의 화제 수가 같게 나오므로, 다른 토픽 모델링을 모색할 필요가 있다.
  
  * 향후 연구에서는 더욱 정교한 토픽 모델링의 실험을 할 예정이며, 이를 통해 주제 수를 자동화 하는 방법을 모색할 것이다.
   
